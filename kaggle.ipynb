{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install typeguard\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = '../input/nbme-score-clinical-patient-notes'\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    # feature_num, case_num, feature_text\n",
    "    features_path: Path = Path(f\"{dataset}/features.csv\")\n",
    "    # pn_num, case_num, pn_history\n",
    "    patient_notes_path: Path = Path(f\"{dataset}/patient_notes.csv\")\n",
    "    # id, case_num, pn_num, feature_num, annotation, location\n",
    "    train_path: Path = Path(f\"{dataset}/train.csv\")\n",
    "    # id, case_num, pn_num, feature_num, annotation, location\n",
    "    test_path: Path = Path(f\"{dataset}/test.csv\")\n",
    "    # id, location\n",
    "    submission_path: Path = Path(f\"submission.csv\")\n",
    "    # model\n",
    "    # model: str = 'bert-base-uncased'\n",
    "    model: str = '../input/huggingface-bert/bert-base-uncased'\n",
    "    # token size\n",
    "    token_size: int = 416\n",
    "    # batch size (default: 8)\n",
    "    batch_size: int = 8\n",
    "    # device: 'cpu' or 'cuda'\n",
    "    # device: str = 'cuda'\n",
    "    device: str = 'cuda'\n",
    "    # span thres\n",
    "    span_thres: float = 0.5\n",
    "    # epochs\n",
    "    epochs: int = 1\n",
    "    # debug?\n",
    "    debug: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Tuple\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def parse_location(location: str) -> List[Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    \"['682 688;695 697']\" -> [(682, 688), (695, 697)]\n",
    "    \"\"\"\n",
    "    def parse(spans: str) -> str:\n",
    "        loc_strs = spans.split(\";\")\n",
    "        for loc in loc_strs:\n",
    "            start, end = loc.split()\n",
    "            return (int(start), int(end))\n",
    "\n",
    "    lst = literal_eval(location)\n",
    "    return list(map(parse, lst))\n",
    "\n",
    "\n",
    "def train_test_split(df: pd.DataFrame, test_ratio: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    assert(0.0 <= test_ratio <= 1.0)\n",
    "    shuffle_df = df.sample(frac=1)\n",
    "    train_size = int((1.0 - test_ratio) * len(df))\n",
    "    return shuffle_df[:train_size], shuffle_df[train_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def preprocess_question(text: str) -> str:\n",
    "    # TODO\n",
    "    return text.replace(\"-OR-\", \"; \").replace(\"-\", \" \")\n",
    "\n",
    "def tokenize_and_add_labels(\n",
    "    tokenizer: AutoTokenizer,\n",
    "    data: pd.Series,\n",
    "    config: Config,\n",
    ") -> pd.DataFrame:\n",
    "    out = tokenizer(\n",
    "        data[\"feature_text\"],\n",
    "        data[\"pn_history\"],\n",
    "        # 文の2番目の切り捨てを行う\n",
    "        truncation=\"only_second\",\n",
    "        max_length=config.token_size,\n",
    "        # 最大長でpaddingする\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    # input_ids: トークンIDのリスト\n",
    "    # token_type_ids: 文の種類を表すマスク(0, 1)\n",
    "    labels = [0.0] * len(out[\"input_ids\"])\n",
    "    out[\"sequence_ids\"] = out.sequence_ids()\n",
    "\n",
    "    for idx, (seq_id, offsets) in enumerate(zip(out[\"sequence_ids\"], out[\"offset_mapping\"])):\n",
    "        is_test_data = 'location' not in data.index\n",
    "        if not seq_id or seq_id == 0 or is_test_data:\n",
    "            labels[idx] = -1\n",
    "            continue\n",
    "\n",
    "        token_start, token_end = offsets\n",
    "        for feature_start, feature_end in data[\"location\"]:\n",
    "            if token_start >= feature_start and token_end <= feature_end:\n",
    "                labels[idx] = 1.0\n",
    "                break\n",
    "\n",
    "    out[\"labels\"] = labels\n",
    "    return out\n",
    "\n",
    "\n",
    "def loopup(df, ref_df, key_label: str, value_label: str) -> pd.DataFrame:\n",
    "    df[value_label] = df.merge(\n",
    "        ref_df[[key_label, value_label]], on=key_label, how='right')[value_label]\n",
    "    return df\n",
    "\n",
    "\n",
    "def join_dfs(df, features, patient_notes):\n",
    "    df = loopup(df, features, 'feature_num', 'feature_text')\n",
    "    df = loopup(df, patient_notes, 'pn_num', 'pn_history')\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_test_dataset(config: Config) -> pd.DataFrame:\n",
    "    features = pd.read_csv(config.features_path)\n",
    "    patient_notes = pd.read_csv(config.patient_notes_path)\n",
    "    test = pd.read_csv(config.test_path)\n",
    "\n",
    "    test = join_dfs(test, features, patient_notes)\n",
    "    test = test[[\"id\", \"pn_history\", \"feature_text\"]]\n",
    "    return test\n",
    "\n",
    "\n",
    "def make_dataset(config: Config) -> pd.DataFrame:\n",
    "    features = pd.read_csv(config.features_path)\n",
    "    patient_notes = pd.read_csv(config.patient_notes_path)\n",
    "    train = pd.read_csv(config.train_path)\n",
    "\n",
    "    train = join_dfs(train, features, patient_notes)\n",
    "    train['location'] = train['location'].apply(parse_location)\n",
    "    train = train[[\"id\", \"pn_history\",\n",
    "                   \"feature_text\", \"annotation\", 'location']]\n",
    "    train['feature_text'] = train['feature_text'].apply(preprocess_question)\n",
    "\n",
    "    print(train.head())\n",
    "    if config.debug:\n",
    "        return train.iloc[:10, :]\n",
    "    else:\n",
    "        return train\n",
    "\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer: AutoTokenizer, config: Config):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.config = config\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data.iloc[idx]\n",
    "        tokens = tokenize_and_add_labels(self.tokenizer, data, self.config)\n",
    "\n",
    "        input_ids = np.array(tokens[\"input_ids\"])\n",
    "        attention_mask = np.array(tokens[\"attention_mask\"])\n",
    "        token_type_ids = np.array(tokens[\"token_type_ids\"])\n",
    "\n",
    "        labels = np.array(tokens[\"labels\"])\n",
    "        offset_mapping = np.array(tokens['offset_mapping'])\n",
    "        sequence_ids = np.array(tokens['sequence_ids']).astype(\"float16\")\n",
    "\n",
    "        return input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "from typeguard import typechecked\n",
    "\n",
    "class QAModel(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(config.model)\n",
    "        dropout = 0.2\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.config = config\n",
    "        self.fc1 = nn.Linear(768, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 1)\n",
    "\n",
    "    @typechecked\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        attention_mask,\n",
    "        token_type_ids,\n",
    "    ):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        hidden = outputs.last_hidden_state\n",
    "        logits = self.fc1(hidden)\n",
    "        logits = self.fc2(self.dropout(logits))\n",
    "        logits = self.fc3(self.dropout(logits))\n",
    "        logits = logits.squeeze(-1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from itertools import chain\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Metrics:\n",
    "    accuracy: float\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "\n",
    "\n",
    "def eval_model(\n",
    "    config: Config,\n",
    "    model: QAModel,\n",
    "    dataloader: DataLoader,\n",
    "    criterion\n",
    ") -> Tuple[float, Metrics]:\n",
    "    \"\"\"\n",
    "    how to evaluation\n",
    "    https://www.kaggle.com/c/nbme-score-clinical-patient-notes/overview/evaluation\n",
    "    \"\"\"\n",
    "    DEVICE = torch.device(config.device)\n",
    "    model.eval()\n",
    "\n",
    "    valid_loss = []\n",
    "    preds = []\n",
    "    offsets = []\n",
    "    seq_ids = []\n",
    "    valid_labels = []\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids = batch\n",
    "        input_ids = input_ids.to(DEVICE)\n",
    "        attention_mask = attention_mask.to(DEVICE)\n",
    "        token_type_ids = token_type_ids.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        logits = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss = torch.masked_select(loss, labels > -1.0).mean()\n",
    "        valid_loss.append(loss.item() * input_ids.size(0))\n",
    "\n",
    "        preds.append(logits.detach().cpu().numpy())\n",
    "        offsets.append(offset_mapping.numpy())\n",
    "        seq_ids.append(sequence_ids.numpy())\n",
    "        valid_labels.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    offsets = np.concatenate(offsets, axis=0)\n",
    "    seq_ids = np.concatenate(seq_ids, axis=0)\n",
    "    valid_labels = np.concatenate(valid_labels, axis=0)\n",
    "\n",
    "    location_preds = get_location_predictions(\n",
    "        preds, offsets, seq_ids, config.span_thres)\n",
    "    score = calculate_char_cv(location_preds, offsets, seq_ids, valid_labels)\n",
    "\n",
    "    return sum(valid_loss)/len(valid_loss), score\n",
    "\n",
    "\n",
    "def get_location_predictions(\n",
    "    # NdArray['test_size', 'token_size']\n",
    "    preds,\n",
    "    # NdArray['test_size', 'token_size', 2]\n",
    "    # 各単語の [開始index, 終了index]\n",
    "    offset_mapping,\n",
    "    # TensorType['test_size', 'token_size']\n",
    "    # question: 0, context: 1, otherwize: nan\n",
    "    sequence_ids,\n",
    "    thres: float = 0.5,\n",
    ") -> List[List[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    preds -> spans: List['test_size', 'span_count']\n",
    "    \"\"\"\n",
    "    all_spans: List[List[Tuple[int, int]]] = []\n",
    "    for pred, offsets, seq_ids in zip(preds, offset_mapping, sequence_ids):\n",
    "        # logitsからprobabilityを計算\n",
    "        pred = 1 / (1 + np.exp(-pred))\n",
    "\n",
    "        start_idx = None\n",
    "        end_idx = None\n",
    "        current_preds: List[Tuple[int, int]] = []\n",
    "        # print(pred, offsets, seq_ids)\n",
    "        for pr, offset, seq_id in zip(pred, offsets, seq_ids):\n",
    "            if seq_id is None or seq_id == 0:\n",
    "                continue\n",
    "\n",
    "            if pr > thres:\n",
    "                if start_idx is None:\n",
    "                    start_idx = offset[0]\n",
    "                end_idx = offset[1]\n",
    "            elif start_idx is not None:\n",
    "                current_preds.append((start_idx, end_idx))\n",
    "                start_idx = None\n",
    "        all_spans.append(current_preds)\n",
    "\n",
    "    return all_spans\n",
    "\n",
    "\n",
    "def calculate_char_cv(\n",
    "    predictions: List[List[Tuple[int, int]]],\n",
    "    # NdArray['test_size', 'token_size', 2]\n",
    "    offset_mapping: np.ndarray,\n",
    "    # NdArray['test_size', 'token_size']\n",
    "    sequence_ids: np.ndarray,\n",
    "    # NdArray['test_size', 'token_size']\n",
    "    labels: np.ndarray,\n",
    ") -> Metrics:\n",
    "    \"\"\"\n",
    "    文字単位で評価値を計算する\n",
    "    \"\"\"\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    for preds, offsets, seq_ids, labels in zip(predictions, offset_mapping, sequence_ids, labels):\n",
    "        num_chars = max(list(chain(*offsets)))\n",
    "        char_labels = np.zeros(num_chars)\n",
    "\n",
    "        # ラベル\n",
    "        for o, s_id, label in zip(offsets, seq_ids, labels):\n",
    "            if s_id is None or s_id == 0:\n",
    "                continue\n",
    "            if int(label) == 1:\n",
    "                char_labels[o[0]:o[1]] = 1\n",
    "\n",
    "        char_preds = np.zeros(num_chars)\n",
    "\n",
    "        # 予測結果\n",
    "        for start_idx, end_idx in preds:\n",
    "            char_preds[start_idx:end_idx] = 1\n",
    "\n",
    "        all_labels.extend(char_labels)\n",
    "        all_preds.extend(char_preds)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_preds, average=\"binary\", labels=np.unique(all_preds))\n",
    "    accuracy: float = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    return Metrics(accuracy, precision, recall, f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    config: Config,\n",
    "    model: QAModel,\n",
    "    dataloader: DataLoader,\n",
    "    optimizer,\n",
    "    criterion\n",
    ") -> float:\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "\n",
    "    DEVICE = config.device\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids = batch\n",
    "\n",
    "        # [batch, token_size]\n",
    "        input_ids = input_ids.to(DEVICE)\n",
    "        attention_mask = attention_mask.to(DEVICE)\n",
    "        token_type_ids = token_type_ids.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        logits = model(input_ids, attention_mask, token_type_ids)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        loss = torch.masked_select(loss, labels > -1.0).mean()\n",
    "        train_loss.append(loss.item() * input_ids.size(0))\n",
    "        loss.backward()\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        # it's also improve f1 accuracy slightly\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "    return sum(train_loss) / len(train_loss)\n",
    "\n",
    "\n",
    "def train(config: Config):\n",
    "    \"\"\"\n",
    "    train & save model \n",
    "    \"\"\"\n",
    "    df = make_dataset(config)\n",
    "    train, test = train_test_split(df, 0.3)\n",
    "    print(f'train: {len(train)}, test: {len(test)}')\n",
    "    DEVICE = torch.device(config.device)\n",
    "    model = QAModel(config).to(DEVICE)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model)\n",
    "\n",
    "    train_dataset = QADataset(train, tokenizer, config)\n",
    "    test_dataset = QADataset(test, tokenizer, config)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "\n",
    "    lr = 1e-5\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses: List[float] = []\n",
    "    valid_losses: List[float] = []\n",
    "\n",
    "    for i in range(config.epochs):\n",
    "        print(f\"epoch: {i + 1}/{config.epochs}\")\n",
    "\n",
    "        train_loss = train_model(\n",
    "            config, model, train_dataloader, optimizer, criterion)\n",
    "        train_losses.append(train_loss)\n",
    "        print(f\"train/loss: {train_loss}\")\n",
    "\n",
    "        valid_loss, metrics = eval_model(\n",
    "            config, model, test_dataloader, criterion)\n",
    "        valid_losses.append(valid_loss)\n",
    "        print(f\"valid/loss: {valid_loss}\")\n",
    "        print(f\"valid/metrics: {metrics}\")\n",
    "\n",
    "    torch.save(model.to('cpu').state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualize(config: Config, logits: torch.Tensor):\n",
    "    \"\"\"\n",
    "    render probablity distribution\n",
    "    \"\"\"\n",
    "    assert len(logits.shape) == 1\n",
    "    preds = 1 / (1 + np.exp(-logits[0]))\n",
    "    n = len(preds)\n",
    "\n",
    "    plt.xlabel('token index')\n",
    "    plt.ylabel('pr')\n",
    "    plt.plot(range(n), preds)\n",
    "    plt.hlines(config.span_thres, 0, n)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def predict(\n",
    "    config: Config,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    model: QAModel,\n",
    "    series: pd.Series,\n",
    ") -> Tuple[np.ndarray, List[Tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    データ1つ -> 予測スパンとlogits\n",
    "    \"\"\"\n",
    "    DEVICE = torch.device(config.device)\n",
    "    tokens = tokenize_and_add_labels(tokenizer, series, config)\n",
    "    # batch-rize ['token_size'] -> [1, 'token_size']\n",
    "    input_ids = torch.LongTensor(np.array(tokens[\"input_ids\"])) \\\n",
    "        .unsqueeze(0).to(DEVICE)\n",
    "    # [1, 'token_size']\n",
    "    attention_mask = torch.LongTensor(\n",
    "        np.array(tokens[\"attention_mask\"])).unsqueeze(0).to(DEVICE)\n",
    "    # [1, 'token_size']\n",
    "    token_type_ids = torch.LongTensor(\n",
    "        np.array(tokens[\"token_type_ids\"])).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    # [1, 'token_size']\n",
    "    logits = model(input_ids, attention_mask, token_type_ids)\n",
    "    assert logits.shape == (1, config.token_size)\n",
    "    # torch.Tensor -> numpy.ndarray\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    # [1, 'token_size']\n",
    "    batched_offset_mapping = np.array(tokens['offset_mapping'])[np.newaxis, :]\n",
    "    batched_sequence_ids = np.array(tokens['sequence_ids'])[np.newaxis, :]\n",
    "\n",
    "    assert batched_offset_mapping.shape == (1, config.token_size, 2)\n",
    "    assert batched_sequence_ids.shape == (1, config.token_size)\n",
    "\n",
    "    spans = get_location_predictions(\n",
    "        logits, batched_offset_mapping, batched_sequence_ids, config.span_thres)[0]\n",
    "    return logits[0], spans\n",
    "\n",
    "\n",
    "def test(config: Config):\n",
    "    \"\"\"\n",
    "    TODO: dump submission.csv\n",
    "    \"\"\"\n",
    "    test = make_test_dataset(config)\n",
    "\n",
    "    model_path = 'model.pth'\n",
    "    model = QAModel(config)\n",
    "    model.load_state_dict(torch.load(\n",
    "        model_path, map_location=torch.device('cpu')))\n",
    "    DEVICE = torch.device(config.device)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model)\n",
    "\n",
    "    submission = test['id'].to_frame()\n",
    "\n",
    "    for idx, series in test.iterrows():\n",
    "        logits, spans = predict(config, tokenizer, model, series)\n",
    "        submission.loc[idx, 'location'] = ';'.join(\n",
    "            map(lambda span: f'{span[0]} {span[1]}', spans)\n",
    "        )\n",
    "        print(spans)\n",
    "        # visualize(config, logits)\n",
    "\n",
    "    submission.to_csv(config.submission_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "config = Config()\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(config)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
