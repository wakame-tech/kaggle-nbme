{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers pandas scikit-learn typeguard matplotlib","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:23:54.797275Z","iopub.execute_input":"2022-05-03T04:23:54.797959Z","iopub.status.idle":"2022-05-03T04:24:24.776915Z","shell.execute_reply.started":"2022-05-03T04:23:54.797826Z","shell.execute_reply":"2022-05-03T04:24:24.776084Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.is_available()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:24:54.243311Z","iopub.execute_input":"2022-05-03T04:24:54.243597Z","iopub.status.idle":"2022-05-03T04:24:55.709764Z","shell.execute_reply.started":"2022-05-03T04:24:54.243564Z","shell.execute_reply":"2022-05-03T04:24:55.709053Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom pathlib import Path\n\ndataset = '../input/nbme-score-clinical-patient-notes'\n\n@dataclass\nclass Config:\n    # feature_num, case_num, feature_text\n    features_path: Path = Path(f\"{dataset}/features.csv\")\n    # pn_num, case_num, pn_history\n    patient_notes_path: Path = Path(f\"{dataset}/patient_notes.csv\")\n    # id, case_num, pn_num, feature_num, annotation, location\n    train_path: Path = Path(f\"{dataset}/train.csv\")\n    # id, case_num, pn_num, feature_num, annotation, location\n    test_path: Path = Path(f\"{dataset}/test.csv\")\n    # id, location\n    submission_path: Path = Path(f\"submission.csv\")\n    # model\n    model: str = '../input/deberta/base'\n    # token size\n    token_size: int = 416\n    # batch size (default: 8)\n    batch_size: int = 8\n    # device: 'cpu' or 'cuda'\n    # device: str = 'cuda'\n    device: str = 'cuda'\n    # span thres\n    span_thres: float = 0.4\n    # epochs\n    epochs: int = 10\n    # debug?\n    debug: bool = False","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:31:34.989438Z","iopub.execute_input":"2022-05-03T04:31:34.989708Z","iopub.status.idle":"2022-05-03T04:31:34.999638Z","shell.execute_reply.started":"2022-05-03T04:31:34.989680Z","shell.execute_reply":"2022-05-03T04:31:34.997070Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"\nfrom typing import List, Tuple\nfrom ast import literal_eval\nimport pandas as pd\n\n\ndef parse_location(location: str) -> List[Tuple[int, int]]:\n    \"\"\"\n    \"['682 688;695 697']\" -> [(682, 688), (695, 697)]\n    \"\"\"\n    def parse(spans: str) -> str:\n        loc_strs = spans.split(\";\")\n        for loc in loc_strs:\n            start, end = loc.split()\n            return (int(start), int(end))\n\n    lst = literal_eval(location)\n    return list(map(parse, lst))\n\n\ndef train_test_split(df: pd.DataFrame, test_ratio: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n    assert(0.0 <= test_ratio <= 1.0)\n    shuffle_df = df.sample(frac=1)\n    train_size = int((1.0 - test_ratio) * len(df))\n    return shuffle_df[:train_size], shuffle_df[train_size:]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:25:02.086380Z","iopub.execute_input":"2022-05-03T04:25:02.087115Z","iopub.status.idle":"2022-05-03T04:25:02.095569Z","shell.execute_reply.started":"2022-05-03T04:25:02.087074Z","shell.execute_reply":"2022-05-03T04:25:02.094455Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset\nfrom transformers import AutoTokenizer\n\n\ndef tokenize_and_add_labels(\n    tokenizer: AutoTokenizer,\n    data: pd.Series,\n    config: Config,\n) -> pd.DataFrame:\n    out = tokenizer(\n        data[\"feature_text\"],\n        data[\"pn_history\"],\n        # 文の2番目の切り捨てを行う\n        truncation=\"only_second\",\n        max_length=config.token_size,\n        # 最大長でpaddingする\n        padding='max_length',\n        return_token_type_ids=True,\n        return_offsets_mapping=True\n    )\n    # input_ids: トークンIDのリスト\n    # token_type_ids: 文の種類を表すマスク(0, 1)\n    labels = [0.0] * len(out[\"input_ids\"])\n    out[\"sequence_ids\"] = out.sequence_ids()\n\n    for idx, (seq_id, offsets) in enumerate(zip(out[\"sequence_ids\"], out[\"offset_mapping\"])):\n        is_test_data = 'location' not in data.index\n        if not seq_id or seq_id == 0 or is_test_data:\n            labels[idx] = -1\n            continue\n\n        token_start, token_end = offsets\n        for feature_start, feature_end in data[\"location\"]:\n            if token_start >= feature_start and token_end <= feature_end:\n                labels[idx] = 1.0\n                break\n\n    out[\"labels\"] = labels\n    return out\n\n\ndef loopup(df, ref_df, key_label: str, value_label: str) -> pd.DataFrame:\n    df[value_label] = df.merge(\n        ref_df[[key_label, value_label]], on=key_label, how='right')[value_label]\n    return df\n\n\ndef join_dfs(df, features, patient_notes):\n    df = loopup(df, features, 'feature_num', 'feature_text')\n    df = loopup(df, patient_notes, 'pn_num', 'pn_history')\n    return df\n\n\ndef make_test_dataset(config: Config) -> pd.DataFrame:\n    features = pd.read_csv(config.features_path)\n    patient_notes = pd.read_csv(config.patient_notes_path)\n    test = pd.read_csv(config.test_path)\n\n    test = join_dfs(test, features, patient_notes)\n    test = test[[\"id\", \"pn_history\", \"feature_text\"]]\n    return test\n\n\ndef make_dataset(config: Config) -> pd.DataFrame:\n    features = pd.read_csv(config.features_path)\n    patient_notes = pd.read_csv(config.patient_notes_path)\n    train = pd.read_csv(config.train_path)\n\n    train = join_dfs(train, features, patient_notes)\n    train['location'] = train['location'].apply(parse_location)\n    train = train[[\"id\", \"pn_history\",\n                   \"feature_text\", \"annotation\", 'location']]\n\n    if config.debug:\n        return pd.DataFrame(train.sample(n = 1000))\n    else:\n        return train\n\n\nclass QADataset(Dataset):\n    def __init__(self, data: pd.DataFrame, tokenizer: AutoTokenizer, config: Config):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.config = config\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        data = self.data.iloc[idx]\n        tokens = tokenize_and_add_labels(self.tokenizer, data, self.config)\n\n        input_ids = np.array(tokens[\"input_ids\"])\n        attention_mask = np.array(tokens[\"attention_mask\"])\n        token_type_ids = np.array(tokens[\"token_type_ids\"])\n\n        labels = np.array(tokens[\"labels\"])\n        offset_mapping = np.array(tokens['offset_mapping'])\n        sequence_ids = np.array(tokens['sequence_ids']).astype(\"float16\")\n\n        return input_ids, attention_mask, token_type_ids, labels, offset_mapping, sequence_ids\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:25:20.677318Z","iopub.execute_input":"2022-05-03T04:25:20.677771Z","iopub.status.idle":"2022-05-03T04:25:20.699954Z","shell.execute_reply.started":"2022-05-03T04:25:20.677737Z","shell.execute_reply":"2022-05-03T04:25:20.699244Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import AutoModel\n\nclass QAModel(nn.Module):\n    def __init__(self, config: Config):\n        super().__init__()\n\n        self.bert = AutoModel.from_pretrained(config.model)\n        dropout = 0.2\n        self.dropout = nn.Dropout(p=dropout)\n        self.config = config\n        self.fc1 = nn.Linear(768, 512)\n        self.fc2 = nn.Linear(512, 512)\n        self.fc3 = nn.Linear(512, 1)\n\n    def forward(\n        self,\n        input_ids,\n        attention_mask,\n        token_type_ids,\n    ):\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids\n        )\n        hidden = outputs.last_hidden_state\n        logits = self.fc1(hidden)\n        logits = self.fc2(self.dropout(logits))\n        logits = self.fc3(self.dropout(logits))\n        logits = logits.squeeze(-1)\n        return logits\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:25:23.204397Z","iopub.execute_input":"2022-05-03T04:25:23.205192Z","iopub.status.idle":"2022-05-03T04:25:23.222495Z","shell.execute_reply.started":"2022-05-03T04:25:23.205152Z","shell.execute_reply":"2022-05-03T04:25:23.221841Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom itertools import chain\nfrom typing import List, Tuple\n\nimport numpy as np\nimport torch\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\n\n\n@dataclass\nclass Metrics:\n    accuracy: float\n    precision: float\n    recall: float\n    f1: float\n\n\ndef eval_model(\n    epoch: int,\n    config: Config,\n    model: QAModel,\n    dataloader: DataLoader,\n    criterion,\n    writer,\n):\n    \"\"\"\n    how to evaluation\n    https://www.kaggle.com/c/nbme-score-clinical-patient-notes/overview/evaluation\n    \"\"\"\n    DEVICE = torch.device(config.device)\n    model.eval()\n\n    valid_loss = []\n    preds = []\n    offsets = []\n    seq_ids = []\n    valid_labels = []\n\n    for i, batch in enumerate(tqdm(dataloader)):\n        (\n            input_ids,\n            attention_mask,\n            token_type_ids,\n            labels,\n            offset_mapping,\n            sequence_ids,\n        ) = batch\n        input_ids = input_ids.to(DEVICE)\n        attention_mask = attention_mask.to(DEVICE)\n        token_type_ids = token_type_ids.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        logits = model(\n            input_ids, attention_mask, token_type_ids\n        )\n\n        loss = criterion(logits, labels)\n        loss = torch.masked_select(loss, labels > -1.0).mean()\n\n        valid_loss = loss.item() * input_ids.size(0)\n        writer.add_scalar(\"valid/loss\", valid_loss, epoch * len(dataloader) + i)\n\n        preds.append(logits.detach().cpu().numpy())\n        offsets.append(offset_mapping.numpy())\n        seq_ids.append(sequence_ids.numpy())\n        valid_labels.append(labels.detach().cpu().numpy())\n\n    preds = np.concatenate(preds, axis=0)\n    offsets = np.concatenate(offsets, axis=0)\n    seq_ids = np.concatenate(seq_ids, axis=0)\n    valid_labels = np.concatenate(valid_labels, axis=0)\n\n    location_preds = get_location_predictions(\n        preds, offsets, seq_ids, config.span_thres\n    )\n    score = calculate_char_cv(location_preds, offsets, seq_ids, valid_labels)\n    return score\n\n\ndef get_location_predictions(\n    # NdArray['test_size', 'token_size']\n    preds,\n    # NdArray['test_size', 'token_size', 2]\n    # 各単語の [開始index, 終了index]\n    offset_mapping,\n    # TensorType['test_size', 'token_size']\n    # question: 0, context: 1, otherwize: nan\n    sequence_ids,\n    thres: float = 0.5,\n) -> List[List[Tuple[int, int]]]:\n    \"\"\"\n    preds -> spans: List['test_size', 'span_count']\n    \"\"\"\n    all_spans: List[List[Tuple[int, int]]] = []\n    for pred, offsets, seq_ids in zip(preds, offset_mapping, sequence_ids):\n        # logitsからprobabilityを計算\n        pred = 1 / (1 + np.exp(-pred))\n\n        start_idx = None\n        end_idx = None\n        current_preds: List[Tuple[int, int]] = []\n        # print(pred, offsets, seq_ids)\n        for pr, offset, seq_id in zip(pred, offsets, seq_ids):\n            if seq_id is None or seq_id == 0:\n                continue\n\n            if pr > thres:\n                if start_idx is None:\n                    start_idx = offset[0]\n                end_idx = offset[1]\n            elif start_idx is not None:\n                current_preds.append((start_idx, end_idx))\n                start_idx = None\n        all_spans.append(current_preds)\n\n    return all_spans\n\n\ndef calculate_char_cv(\n    predictions: List[List[Tuple[int, int]]],\n    # NdArray['test_size', 'token_size', 2]\n    offset_mapping: np.ndarray,\n    # NdArray['test_size', 'token_size']\n    sequence_ids: np.ndarray,\n    # NdArray['test_size', 'token_size']\n    labels: np.ndarray,\n) -> Metrics:\n    \"\"\"\n    文字単位で評価値を計算する\n    \"\"\"\n    all_labels = []\n    all_preds = []\n    for preds, offsets, seq_ids, labels in zip(\n        predictions, offset_mapping, sequence_ids, labels\n    ):\n        num_chars = max(list(chain(*offsets)))\n        char_labels = np.zeros(num_chars)\n\n        # ラベル\n        for o, s_id, label in zip(offsets, seq_ids, labels):\n            if s_id is None or s_id == 0:\n                continue\n            if int(label) == 1:\n                char_labels[o[0] : o[1]] = 1\n\n        char_preds = np.zeros(num_chars)\n\n        # 予測結果\n        for start_idx, end_idx in preds:\n            char_preds[start_idx:end_idx] = 1\n\n        all_labels.extend(char_labels)\n        all_preds.extend(char_preds)\n\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        all_labels, all_preds, average=\"binary\", labels=np.unique(all_preds)\n    )\n    accuracy: float = accuracy_score(all_labels, all_preds)\n\n    return Metrics(accuracy, precision, recall, f1)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:25:26.264226Z","iopub.execute_input":"2022-05-03T04:25:26.264608Z","iopub.status.idle":"2022-05-03T04:25:26.808243Z","shell.execute_reply.started":"2022-05-03T04:25:26.264572Z","shell.execute_reply":"2022-05-03T04:25:26.807524Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from typing import List, Tuple\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\nfrom transformers import AutoTokenizer\n\n\ndef train_model(\n    epoch: int,\n    config: Config,\n    model: QAModel,\n    dataloader: DataLoader,\n    optimizer,\n    criterion,\n    writer,\n):\n    model.train()\n    train_loss = []\n\n    DEVICE = config.device\n\n    for i, batch in enumerate(tqdm(dataloader)):\n        optimizer.zero_grad()\n        (\n            input_ids,\n            attention_mask,\n            token_type_ids,\n            labels,\n            offset_mapping,\n            sequence_ids,\n        ) = batch\n\n        # [batch, token_size]\n        input_ids = input_ids.to(DEVICE)\n        attention_mask = attention_mask.to(DEVICE)\n        token_type_ids = token_type_ids.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        logits = model(input_ids, attention_mask, token_type_ids)\n        loss = criterion(logits, labels)\n\n        loss = torch.masked_select(loss, labels > -1.0).mean()\n\n        train_loss = loss.item() * input_ids.size(0)\n        writer.add_scalar(\"train/loss\", train_loss, epoch * len(dataloader) + i)\n\n        loss.backward()\n        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n        # it's also improve f1 accuracy slightly\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n\ndef train(config: Config):\n    \"\"\"\n    train & save model\n    \"\"\"\n    df = make_dataset(config)\n    train, test = train_test_split(df, 0.3)\n    print(f\"train: {len(train)}, test: {len(test)}\")\n    DEVICE = torch.device(config.device)\n    model = QAModel(config).to(DEVICE)\n    tokenizer = AutoTokenizer.from_pretrained(config.model)\n\n    train_dataset = QADataset(train, tokenizer, config)\n    test_dataset = QADataset(test, tokenizer, config)\n\n    train_dataloader = DataLoader(\n        train_dataset, batch_size=config.batch_size, shuffle=True\n    )\n    test_dataloader = DataLoader(\n        test_dataset, batch_size=config.batch_size, shuffle=False\n    )\n\n    criterion = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n\n    lr = 1e-5\n    optimizer = optim.AdamW(model.parameters(), lr=lr)\n\n    writer = SummaryWriter()\n\n    for epoch in range(config.epochs):\n        print(f\"epoch: {epoch + 1}/{config.epochs}\")\n\n        train_model(epoch, config, model, train_dataloader, optimizer, criterion, writer)\n        metrics = eval_model(epoch, config, model, test_dataloader, criterion, writer)\n        writer.add_scalar(\"valid/f1\", metrics.f1, epoch * len(test_dataloader))\n        print(f'f1: {metrics.f1}')\n        writer.add_scalar('valid/acc', metrics.accuracy, epoch * len(test_dataloader))\n        writer.add_scalar('valid/prec', metrics.precision, epoch * len(test_dataloader))\n\n    torch.save(model.to(\"cpu\").state_dict(), \"model.pth\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:32:39.267527Z","iopub.execute_input":"2022-05-03T04:32:39.267791Z","iopub.status.idle":"2022-05-03T04:32:39.283772Z","shell.execute_reply.started":"2022-05-03T04:32:39.267760Z","shell.execute_reply":"2022-05-03T04:32:39.282955Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\nfrom typing import List, Tuple\nimport torch\nimport pandas as pd\nfrom transformers import AutoTokenizer\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef visualize(config: Config, logits: torch.Tensor):\n    \"\"\"\n    render probablity distribution\n    \"\"\"\n    assert len(logits.shape) == 1\n    preds = 1 / (1 + np.exp(-logits[0]))\n    n = len(preds)\n\n    plt.xlabel('token index')\n    plt.ylabel('pr')\n    plt.plot(range(n), preds)\n    plt.hlines(config.span_thres, 0, n)\n    plt.show()\n\n\ndef predict(\n    config: Config,\n    tokenizer: AutoTokenizer,\n    model: QAModel,\n    series: pd.Series,\n) -> Tuple[np.ndarray, List[Tuple[int, int]]]:\n    \"\"\"\n    データ1つ -> 予測スパンとlogits\n    \"\"\"\n    DEVICE = torch.device(config.device)\n    tokens = tokenize_and_add_labels(tokenizer, series, config)\n    # batch-rize ['token_size'] -> [1, 'token_size']\n    input_ids = torch.LongTensor(np.array(tokens[\"input_ids\"])) \\\n        .unsqueeze(0).to(DEVICE)\n    # [1, 'token_size']\n    attention_mask = torch.LongTensor(\n        np.array(tokens[\"attention_mask\"])).unsqueeze(0).to(DEVICE)\n    # [1, 'token_size']\n    token_type_ids = torch.LongTensor(\n        np.array(tokens[\"token_type_ids\"])).unsqueeze(0).to(DEVICE)\n\n    # [1, 'token_size']\n    logits = model(input_ids, attention_mask, token_type_ids)\n    assert logits.shape == (1, config.token_size)\n    # torch.Tensor -> numpy.ndarray\n    logits = logits.detach().cpu().numpy()\n\n    # [1, 'token_size']\n    batched_offset_mapping = np.array(tokens['offset_mapping'])[np.newaxis, :]\n    batched_sequence_ids = np.array(tokens['sequence_ids'])[np.newaxis, :]\n\n    assert batched_offset_mapping.shape == (1, config.token_size, 2)\n    assert batched_sequence_ids.shape == (1, config.token_size)\n\n    spans = get_location_predictions(\n        logits, batched_offset_mapping, batched_sequence_ids, config.span_thres)[0]\n    return logits[0], spans\n\n\ndef test(config: Config):\n    \"\"\"\n    TODO: dump submission.csv\n    \"\"\"\n    test = make_test_dataset(config)\n\n    model_path = 'model.pth'\n    model = QAModel(config)\n    model.load_state_dict(torch.load(\n        model_path, map_location=torch.device('cpu')))\n    DEVICE = torch.device(config.device)\n    model.to(DEVICE)\n    model.eval()\n\n    tokenizer = AutoTokenizer.from_pretrained(config.model)\n\n    submission = test['id'].to_frame()\n\n    for idx, series in test.iterrows():\n        logits, spans = predict(config, tokenizer, model, series)\n        submission.loc[idx, 'location'] = ';'.join(\n            map(lambda span: f'{span[0]} {span[1]}', spans)\n        )\n        print(spans)\n        # visualize(config, logits)\n        \n    del model\n\n    submission.to_csv(config.submission_path, index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:25:31.944773Z","iopub.execute_input":"2022-05-03T04:25:31.945286Z","iopub.status.idle":"2022-05-03T04:25:31.966379Z","shell.execute_reply.started":"2022-05-03T04:25:31.945243Z","shell.execute_reply":"2022-05-03T04:25:31.965298Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"config = Config()\ntrain(config)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:31:42.550012Z","iopub.execute_input":"2022-05-03T04:31:42.550756Z","iopub.status.idle":"2022-05-03T04:31:53.700798Z","shell.execute_reply.started":"2022-05-03T04:31:42.550714Z","shell.execute_reply":"2022-05-03T04:31:53.699700Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"test(config)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T04:20:29.721012Z","iopub.status.idle":"2022-05-03T04:20:29.721291Z","shell.execute_reply.started":"2022-05-03T04:20:29.721142Z","shell.execute_reply":"2022-05-03T04:20:29.721162Z"},"trusted":true},"execution_count":null,"outputs":[]}]}